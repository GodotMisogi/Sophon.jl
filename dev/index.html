<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · Sophon.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://MilkshakeForReal.github.io/Sophon.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>Sophon.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/MilkshakeForReal/Sophon.jl/blob/main/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Sophon"><a class="docs-heading-anchor" href="#Sophon">Sophon</a><a id="Sophon-1"></a><a class="docs-heading-anchor-permalink" href="#Sophon" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/MilkshakeForReal/Sophon.jl">Sophon</a>.</p><ul><li><a href="#Sophon.FourierFeature"><code>Sophon.FourierFeature</code></a></li><li><a href="#Sophon.PINNAttention"><code>Sophon.PINNAttention</code></a></li><li><a href="#Sophon.Sine"><code>Sophon.Sine</code></a></li><li><a href="#Sophon.TriplewiseFusion"><code>Sophon.TriplewiseFusion</code></a></li><li><a href="#Sophon.FourierAttention-Tuple{Int64, Int64, Int64, Any}"><code>Sophon.FourierAttention</code></a></li><li><a href="#Sophon.FullyConnected-Union{Tuple{T}, Tuple{N}, Tuple{Int64, Tuple{Vararg{T, N}}, Function}} where {N, T&lt;:Int64}"><code>Sophon.FullyConnected</code></a></li><li><a href="#Sophon.MultiscaleFourier-Union{Tuple{Int64}, Tuple{S}, Tuple{N2}, Tuple{N1}, Tuple{Int64, Tuple{Vararg{Int64, N1}}}, Tuple{Int64, Tuple{Vararg{Int64, N1}}, Function}, Tuple{Int64, Tuple{Vararg{Int64, N1}}, Function, Tuple{Vararg{Pair{S, Int64}, N2}}}} where {N1, N2, S}"><code>Sophon.MultiscaleFourier</code></a></li><li><a href="#Sophon.Siren-Tuple{Int64, Int64, Int64}"><code>Sophon.Siren</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="Sophon.FourierFeature" href="#Sophon.FourierFeature"><code>Sophon.FourierFeature</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FourierFeature(in_dims::Int, modes::NTuple{N,Pair{S,T}}) where {N,S,T&lt;:Int}</code></pre><p>Fourier Feature Network.</p><p><strong>Arguments</strong></p><ul><li><code>in_dims</code>: Input dimension.</li><li><code>modes</code>: A tuple of pairs of <code>std =&gt; out_dims</code>, where <code>std</code> is the standard deviation of the Gaussian distribution, and <code>out_dims</code> is the output dimension.</li></ul><p><strong>Inputs</strong></p><ul><li><code>x</code>: An an AbstractArray with <code>size(x, 1) == in_dims</code>.</li></ul><p><strong>Returns</strong></p><ul><li>An AbstractArray with <code>size(y, 1) == sum(last(modes) * 2)</code>.</li><li>The states of the layers.</li></ul><p><strong>States</strong></p><ul><li><code>modes</code>: Random frequencies.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">FourierFeature(2, (1 =&gt; 3, 50 =&gt; 4))</code></pre><p><strong>References</strong></p><p>[1] Tancik, Matthew, et al. “Fourier features let networks learn high frequency functions in low dimensional domains.” Advances in Neural Information Processing Systems 33 (2020): 7537-7547.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/Sophon.jl/blob/c98c9412aaeffd59f51d2c173262dbe48176e8a2/src/layers/basic.jl#L1-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.PINNAttention" href="#Sophon.PINNAttention"><code>Sophon.PINNAttention</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PINNAttention(H_net, U_net, V_net, fusion_layers)
PINNAttention(in_dims::Int, hidden_dim::Int, num_layers::Int, activation)</code></pre><p>The output dimesion of <code>H_net</code> and the input dimension of <code>fusion_layers</code> must be the same. For the second and the third constructor, <code>Dense</code> layers is used for <code>H_net</code>, <code>U_net</code>, and <code>V_net</code>.</p><pre><code class="nohighlight hljs">                 x → U_net → u                           u
                               ↘                           ↘
x → H_net →  h1 → fusionlayer1 → connection → fusionlayer2 → connection
                               ↗                           ↗
                 x → V_net → v                           v</code></pre><p><strong>Arguments</strong></p><pre><code class="nohighlight hljs">- `H_net`: `AbstractExplicitLayer`
- `U_net`: `AbstractExplicitLayer`
- `V_net`: `AbstractExplicitLayer`
- `in_dims`: The input dimension.
- `hidden_dims`: The output dimension of `H_net`.
- `fusion_layers`: `AbstractExplicitLayer` or a tuple of integeters. In the latter case,
    fully connected layers are used.</code></pre><p><strong>References</strong></p><p>[1] Wang, Sifan, Yujun Teng, and Paris Perdikaris. &quot;Understanding and mitigating gradient flow pathologies in physics-informed neural networks.&quot; SIAM Journal on Scientific Computing 43.5 (2021): A3055-A3081</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/Sophon.jl/blob/c98c9412aaeffd59f51d2c173262dbe48176e8a2/src/layers/nets.jl#L1-L29">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.Sine" href="#Sophon.Sine"><code>Sophon.Sine</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Sine(in_dims::Int, out_dims::Int, activation=sin; is_first::Bool = false, omega::AbstractFloat = 30f0)</code></pre><p>Sinusoidal layer.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">s = Sine(2, 2; is_first=true) # first layer
s = Sine(2, 2) # hidden layer
s = Sine(2, 2, identity) # last layer</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/Sophon.jl/blob/c98c9412aaeffd59f51d2c173262dbe48176e8a2/src/layers/basic.jl#L206-L218">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.TriplewiseFusion" href="#Sophon.TriplewiseFusion"><code>Sophon.TriplewiseFusion</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">TriplewiseFusion(connection, layers...)</code></pre><pre><code class="nohighlight hljs">         u1                    u2
            ↘                     ↘
h1 → layer1 → connection → layer2 → connection
            ↗                     ↗
         v1                    v2</code></pre><p><strong>Arguments</strong></p><ul><li><code>connection</code>: Takes 3 inputs and combines them</li><li><code>layers</code>: <code>AbstractExplicitLayer</code>s or a <code>Chain</code>.</li></ul><p><strong>Inputs</strong></p><p>Layer behaves differently based on input type:</p><ol><li>A tripe of <code>(h, u, v)</code>, where <code>u</code> and <code>v</code> itself are tuples of length <code>N</code>, the <code>layers</code> is also a tuple of length <code>N</code>. The computation is as follows</li></ol><pre><code class="language-julia hljs">for i in 1:N
    h = connection(layers[i](h), u[i], v[i])
end</code></pre><ol><li>A triple of <code>(h, u, v)</code>, where <code>u</code> and <code>v</code> are <code>AbstractArray</code>s.</li></ol><pre><code class="language-julia hljs">for i in 1:N
    h = connection(layers[i](h), u, v)
end</code></pre><p><strong>Returns</strong></p><ul><li>See Inputs section for how the return value is computed</li><li>Updated model state for all the contained layers</li></ul><p><strong>Parameters</strong></p><ul><li>Parameters of each <code>layer</code> wrapped in a NamedTuple with <code>fields = layer_1, layer_2, ..., layer_N</code></li></ul><p><strong>States</strong></p><ul><li>States of each <code>layer</code> wrapped in a NamedTuple with <code>fields = layer_1, layer_2, ..., layer_N</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/Sophon.jl/blob/c98c9412aaeffd59f51d2c173262dbe48176e8a2/src/layers/basic.jl#L71-L122">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.FourierAttention-Tuple{Int64, Int64, Int64, Any}" href="#Sophon.FourierAttention-Tuple{Int64, Int64, Int64, Any}"><code>Sophon.FourierAttention</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">FourierAttention(in_dims::Int, hidden_dim::Int, num_layers::Int, activation; modes)</code></pre><pre><code class="nohighlight hljs">x → [FourierFeature(x); x] → PINNAttention</code></pre><p><strong>Arguments</strong></p><ul><li><code>in_dims</code>: The input dimension.</li><li><code>hidden_dim</code>: The hidden dimension of each hidden layer.</li><li><code>num_layers</code>: The number of hidden layers.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>modes</code>: A tuple of pairs of random frequencies and the number of samples.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/Sophon.jl/blob/c98c9412aaeffd59f51d2c173262dbe48176e8a2/src/layers/nets.jl#L66-L82">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.FullyConnected-Union{Tuple{T}, Tuple{N}, Tuple{Int64, Tuple{Vararg{T, N}}, Function}} where {N, T&lt;:Int64}" href="#Sophon.FullyConnected-Union{Tuple{T}, Tuple{N}, Tuple{Int64, Tuple{Vararg{T, N}}, Function}} where {N, T&lt;:Int64}"><code>Sophon.FullyConnected</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">FullyConnected(in_dims, hidden_dims::NTuple{N, Int}, activation; outermost = false)
FullyConnected(in_dims, hidden_dims, num_layers, activation; outermost = false)</code></pre><p>Create fully connected layers.</p><p><strong>Arguments</strong></p><ul><li><code>in_dims</code>: Input dimension.</li><li><code>hidden_dims</code>: Hidden dimensions.</li><li><code>num_layers</code>: Number of layers.</li><li><code>activation</code>: Activation function.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>outermost</code>: Whether to use activation function for the last layer.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/Sophon.jl/blob/c98c9412aaeffd59f51d2c173262dbe48176e8a2/src/layers/basic.jl#L167-L183">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.MultiscaleFourier-Union{Tuple{Int64}, Tuple{S}, Tuple{N2}, Tuple{N1}, Tuple{Int64, Tuple{Vararg{Int64, N1}}}, Tuple{Int64, Tuple{Vararg{Int64, N1}}, Function}, Tuple{Int64, Tuple{Vararg{Int64, N1}}, Function, Tuple{Vararg{Pair{S, Int64}, N2}}}} where {N1, N2, S}" href="#Sophon.MultiscaleFourier-Union{Tuple{Int64}, Tuple{S}, Tuple{N2}, Tuple{N1}, Tuple{Int64, Tuple{Vararg{Int64, N1}}}, Tuple{Int64, Tuple{Vararg{Int64, N1}}, Function}, Tuple{Int64, Tuple{Vararg{Int64, N1}}, Function, Tuple{Vararg{Pair{S, Int64}, N2}}}} where {N1, N2, S}"><code>Sophon.MultiscaleFourier</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">MultiscaleFourier(in_dims::Int, out_dims::NTuple, activation=identity, modes::NTuple)</code></pre><p>Multi-scale Fourier Feature Net.</p><pre><code class="nohighlight hljs">x → FourierFeature → FullyConnected → y</code></pre><p><strong>Arguments</strong></p><ul><li><code>in_dims</code>: The number of input dimensions.</li><li><code>out_dims</code>: A tuple of output dimensions used to construct <code>FullyConnected</code>.</li><li><code>activation</code>: The activation function used to construct <code>FullyConnected</code>.</li><li><code>modes</code>: A tuple of modes used to construct <code>FourierFeature</code>.</li></ul><p><strong>References</strong></p><p>[1] Wang, Sifan, Hanwen Wang, and Paris Perdikaris. “On the eigenvector bias of fourier feature networks: From regression to solving multi-scale pdes with physics-informed neural networks.” Computer Methods in Applied Mechanics and Engineering 384 (2021): 113938.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/Sophon.jl/blob/c98c9412aaeffd59f51d2c173262dbe48176e8a2/src/layers/nets.jl#L91-L110">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.Siren-Tuple{Int64, Int64, Int64}" href="#Sophon.Siren-Tuple{Int64, Int64, Int64}"><code>Sophon.Siren</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Siren(in_dims::Int, hidden_dim::Int, num_layers::Int; omega = 30f0)
Siren(in_dims::Int, hidden_dims::NTuple{N, T}; omega = 30f0) where {N, T &lt;: Int}</code></pre><p>Sinusoidal Representation Network.</p><p><strong>Keyword Arguments</strong></p><ul><li><code>omega</code>: The <code>ω₀</code> used for the first layer.</li></ul><p><strong>References</strong></p><p>[1] Sitzmann, Vincent, et al. &quot;Implicit neural representations with periodic activation functions.&quot; Advances in Neural Information Processing Systems 33 (2020): 7462-7473.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/MilkshakeForReal/Sophon.jl/blob/c98c9412aaeffd59f51d2c173262dbe48176e8a2/src/layers/nets.jl#L123-L136">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.22 on <span class="colophon-date" title="Wednesday 10 August 2022 20:42">Wednesday 10 August 2022</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
