<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · Sophon.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://YichengDWu.github.io/Sophon.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script><link href="assets/indigo.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>Sophon.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="tutorials/discontinuous/">Fitting a nonlinear discontinuous function</a></li><li><a class="tocitem" href="tutorials/poisson/">1D Poisson&#39;s Equation</a></li><li><a class="tocitem" href="tutorials/convection/">1D Convection Equation</a></li><li><a class="tocitem" href="tutorials/helmholtz/">2D Helmholtz Equation</a></li><li><a class="tocitem" href="tutorials/allen_cahn/">Allen-Cahn equation with Sequential Trainning</a></li></ul></li><li><a class="tocitem" href="references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/YichengDWu/Sophon.jl/blob/main/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Sophon"><a class="docs-heading-anchor" href="#Sophon">Sophon</a><a id="Sophon-1"></a><a class="docs-heading-anchor-permalink" href="#Sophon" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/YichengDWu/Sophon.jl">Sophon</a>.</p><ul><li><a href="#Sophon.DeepONet"><code>Sophon.DeepONet</code></a></li><li><a href="#Sophon.DiscreteFourierFeature"><code>Sophon.DiscreteFourierFeature</code></a></li><li><a href="#Sophon.FourierFeature"><code>Sophon.FourierFeature</code></a></li><li><a href="#Sophon.NonAdaptiveTraining"><code>Sophon.NonAdaptiveTraining</code></a></li><li><a href="#Sophon.PINN"><code>Sophon.PINN</code></a></li><li><a href="#Sophon.PINNAttention"><code>Sophon.PINNAttention</code></a></li><li><a href="#Sophon.QuasiRandomSampler"><code>Sophon.QuasiRandomSampler</code></a></li><li><a href="#Sophon.RBF"><code>Sophon.RBF</code></a></li><li><a href="#Sophon.TriplewiseFusion"><code>Sophon.TriplewiseFusion</code></a></li><li><a href="#Sophon.BACON-Tuple{Int64, Int64, Int64, Real}"><code>Sophon.BACON</code></a></li><li><a href="#Sophon.FourierAttention"><code>Sophon.FourierAttention</code></a></li><li><a href="#Sophon.FourierFilterNet-Tuple{Int64, Int64}"><code>Sophon.FourierFilterNet</code></a></li><li><a href="#Sophon.FourierNet-Union{Tuple{T}, Tuple{N}, Tuple{Tuple{Vararg{T, N}}, Function, Tuple{Vararg{T, N}} where {N, T}}} where {N, T&lt;:Int64}"><code>Sophon.FourierNet</code></a></li><li><a href="#Sophon.FullyConnected-Union{Tuple{T}, Tuple{N}, Tuple{Tuple{Vararg{T, N}}, Function}} where {N, T&lt;:Int64}"><code>Sophon.FullyConnected</code></a></li><li><a href="#Sophon.Sine-Union{Tuple{Pair{T, T}}, Tuple{T}} where T&lt;:Int64"><code>Sophon.Sine</code></a></li><li><a href="#Sophon.Siren-Tuple{Int64, Int64}"><code>Sophon.Siren</code></a></li><li><a href="#Sophon.gaussian"><code>Sophon.gaussian</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="Sophon.DeepONet" href="#Sophon.DeepONet"><code>Sophon.DeepONet</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DeepONet(branch_net, trunk_net;
         flatten_layer=FlattenLayer(),
         linear_layer=NoOpLayer(),
         bias=Scalar())
DeepONet(layer_sizes_branch, activation_branch,
         layer_sizes_trunk,
         activation_trunk,
         layer_sizes_linear=nothing)</code></pre><p>Deep operator network. Note that the branch net supports multi-dimensional inputs. The <code>flatten_layer</code> flatten the output of the branch net to a matrix, and the <code>linear_layer</code> is applied to the flattened. In this case, <code>linear_layer</code> must be given to transform the flattened matrix to the correct shape.</p><pre><code class="nohighlight hljs">v → branch_net → flatten_layer → linear_layer → b
                                                  ↘
                                                    b&#39; * t + bias → u
                                                  ↗
                                ξ → trunk_net → t</code></pre><p><strong>Arguments</strong></p><ul><li><code>branch_net</code>: The branch net.</li><li><code>trunk_net</code>: The trunk net.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>flatten_layer</code>: The layer to flatten a multi-dimensional array to a matrix.</li><li><code>linear_layer</code>: The layer to apply a linear transformation to the output of the <code>flatten_layer</code>.</li></ul><p><strong>Inputs</strong></p><ul><li><code>(v, ξ)</code>: <code>v</code> is an array of shape <span>$(b_1,b_2,...b_d, m)$</span>, where <code>d</code> is the dimension of the input function, and <code>m</code> is the number of input functions. <code>ξ</code> is a matrix of shape <span>$(d&#39;, n)$</span>, where <span>$d&#39;$</span> is the dimension of the output function, and <code>m</code> is the number of &quot;sensors&quot;.</li></ul><p><strong>Returns</strong></p><ul><li>A matrix of shape <span>$(m, n)$</span>.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; deeponet = DeepONet((3, 5, 4), relu, (2, 6, 4, 4), tanh)
DeepONet(
    branch_net = Chain(
        layer_1 = Dense(3 =&gt; 5, relu),  # 20 parameters
        layer_2 = Dense(5 =&gt; 4),        # 24 parameters
    ),
    trunk_net = Chain(
        layer_1 = Dense(2 =&gt; 6, tanh_fast),  # 18 parameters
        layer_2 = Dense(6 =&gt; 4, tanh_fast),  # 28 parameters
        layer_3 = Dense(4 =&gt; 4, tanh_fast),  # 20 parameters
    ),
    flatten_layer = FlattenLayer(),
    linear_layer = NoOpLayer(),
    bias = Scalar(),                    # 1 parameters
)         # Total: 111 parameters,
          #        plus 0 states, summarysize 80 bytes.</code></pre><p><strong>Reference</strong></p><p><a href="references/#lu2019deeponet">Lu Lu, Pengzhan Jin, Guofei Pang, Zhongqiang Zhang, George Em Karniadakis (2021)</a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/layers/operators.jl#L1-L67">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.DiscreteFourierFeature" href="#Sophon.DiscreteFourierFeature"><code>Sophon.DiscreteFourierFeature</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DiscreteFourierFeature(in_dims::Int, out_dims::Int, N::Int, period::Real)</code></pre><p>The discrete Fourier filter proposed in <a href="references/#lindell2021bacon">David B. Lindell, Dave Van Veen, Jeong Joon Park, Gordon Wetzstein (2021)</a>. For a periodic function with period <span>$P$</span>, the Fourier series in amplitude-phase form is</p><p class="math-container">\[s_N(x)=\frac{a_0}{2}+\sum_{n=1}^N{a_n}\cdot \sin \left( \frac{2\pi}{P}nx+\varphi _n \right)\]</p><p>The output is guaranteed to be periodic.</p><p><strong>Arguments</strong></p><ul><li><code>in_dims</code>: Number of the input dimensions.</li><li><code>out_dims</code>: Number of the output dimensions.</li><li><code>N</code>: <span>$N$</span> in the formula.</li><li><code>period</code>: <span>$P$</span> in the formula.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/layers/basic.jl#L118-L133">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.FourierFeature" href="#Sophon.FourierFeature"><code>Sophon.FourierFeature</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FourierFeature(in_dims::Int, std::NTuple{N,Pair{S,T}}) where {N,S,T&lt;:Int}
FourierFeature(in_dims::Int, frequencies::NTuple{N, T}) where {N, T &lt;: Real}
FourierFeature(in_dims::Int, out_dims::Int, std::Real)</code></pre><p>Fourier Feature Network.</p><p><strong>Arguments</strong></p><ul><li><code>in_dims</code>: Number of the input dimensions.</li><li><code>std</code>: A tuple of pairs of <code>sigma =&gt; out_dims</code>, where <code>sigma</code> is the standard deviation of the Gaussian distribution.</li></ul><p class="math-container">\[\phi^{(i)}(x)=\left[\sin \left(2 \pi W^{(i)} x\right) ; \cos 2 \pi W^{(i)} x\right],\ W^{(i)} \sim \mathcal{N}\left(0, \sigma^{(i)}\right),\ i\in 1, \dots, D\]</p><ul><li><code>frequencies</code>: A tuple of frequencies <code>(f1,f2,...,fn)</code>.</li></ul><p class="math-container">\[\phi^{(i)}(x)=\left[\sin \left(2 \pi f_i x\right) ; \cos 2 \pi f_i x\right]\]</p><p><strong>Inputs</strong></p><ul><li><code>x</code>: <code>AbstractArray</code><code>with</code>size(x, 1) == in_dims`.</li></ul><p><strong>Returns</strong></p><ul><li><code>AbstractArray</code> with <code>size(y, 1) == sum(last(modes) * 2)</code>.</li></ul><p><strong>States</strong></p><ul><li>The weight <code>W</code> in case 1, otherwise <code>NamedTuple()</code>.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; f = FourierFeature(2,10,1) # Random Fourier Feature
FourierFeature(2 =&gt; 10)

julia&gt; f = FourierFeature(2, (1 =&gt; 3, 50 =&gt; 4)) # Multi-scale Random Fourier Features
FourierFeature(2 =&gt; 14)

julia&gt;  f = FourierFeature(2, (1,2,3,4)) # Predefined frequencies
FourierFeature(2 =&gt; 16)</code></pre><p><strong>References</strong></p><p><a href="references/#rahimi2007random">Ali Rahimi, Benjamin Recht (2007)</a></p><p><a href="references/#tancik2020fourier">Matthew Tancik, Pratul Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan Barron, Ren Ng (2020)</a></p><p><a href="references/#wang2021eigenvector">Sifan Wang, Hanwen Wang, Paris Perdikaris (2021)</a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/layers/basic.jl#L1-L55">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.NonAdaptiveTraining" href="#Sophon.NonAdaptiveTraining"><code>Sophon.NonAdaptiveTraining</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">NonAdaptiveTraining(pde_weights=1, bcs_weights=pde_weights)</code></pre><p>Fixed weights for the loss functions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/compact/NeuralPDE/training_strategies.jl#L3-L7">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.PINN" href="#Sophon.PINN"><code>Sophon.PINN</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PINN(chain; device_type::Type=Array{Float64})</code></pre><p><strong>Arguments</strong></p><ul><li><code>chain</code>: <code>AbstractExplicitLayer</code> or a named tuple of <code>AbstractExplicitLayer</code>s.</li><li><code>device_type</code>: <code>Array{T}</code> or <code>CuArray{T}</code>, or any other array types.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/compact/NeuralPDE/pinn_types.jl#L1-L8">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.PINNAttention" href="#Sophon.PINNAttention"><code>Sophon.PINNAttention</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">PINNAttention(H_net, U_net, V_net, fusion_layers)
PINNAttention(in_dims::Int, out_dims::Int, activation::Function=sin;
              hidden_dims::Int, num_layers::Int)</code></pre><p>The output dimesion of <code>H_net</code> and the input dimension of <code>fusion_layers</code> must be the same. For the second and the third constructor, <code>Dense</code> layers is used for <code>H_net</code>, <code>U_net</code>, and <code>V_net</code>. Note that the first constructer does not contain the output layer.</p><pre><code class="nohighlight hljs">                 x → U_net → u                           u
                               ↘                           ↘
x → H_net →  h1 → fusionlayer1 → connection → fusionlayer2 → connection
                               ↗                           ↗
                 x → V_net → v                           v</code></pre><p><strong>Arguments</strong></p><ul><li><code>H_net</code>: <code>AbstractExplicitLayer</code>.</li><li><code>U_net</code>: <code>AbstractExplicitLayer</code>.</li><li><code>V_net</code>: <code>AbstractExplicitLayer</code>.</li><li><code>fusion_layers</code>: <code>Chain</code>.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>num_layers</code>: The number of hidden layers.</li><li><code>hidden_dims</code>: The number of hidden dimensions of each hidden layer.</li></ul><p><strong>Reference</strong></p><p><a href="references/#wang2021understanding">Sifan Wang, Yujun Teng, Paris Perdikaris (2021)</a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/layers/nets.jl#L1-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.QuasiRandomSampler" href="#Sophon.QuasiRandomSampler"><code>Sophon.QuasiRandomSampler</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">QuasiRandomSampler(pde_points, bcs_points=pde_points;
                   device_type::Type=Array{Float64}
                   sampling_alg=LatinHypercubeSample())</code></pre><p>Sampler to generate the datasets for PDE and boundary conditions using a quisa-random sampling algorithm. It momerizes the domain of the PDE and the boundary conditions, and you can call <code>sample</code> on it to generate the datasets.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/compact/NeuralPDE/pinnsampler.jl#L10-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.RBF" href="#Sophon.RBF"><code>Sophon.RBF</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">RBF(in_dims::Int, out_dims::Int, num_centers::Int=out_dims; sigma::AbstractFloat=0.2f0)</code></pre><p>Normalized Radial Basis Fuction Network.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/layers/basic.jl#L224-L228">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.TriplewiseFusion" href="#Sophon.TriplewiseFusion"><code>Sophon.TriplewiseFusion</code></a> — <span class="docstring-category">Type</span></header><section><div><p>TriplewiseFusion(connection, layers...)</p><pre><code class="nohighlight hljs">     u1                    u2
        ↘                     ↘
h1 → layer1 → connection → layer2 → connection
        ↗                     ↗
     v1                    v2</code></pre><p><strong>Arguments</strong></p><ul><li><code>connection</code>: A functio takes 3 inputs and combines them.</li><li><code>layers</code>: <code>AbstractExplicitLayer</code>s or a <code>Chain</code>.</li></ul><p><strong>Inputs</strong></p><p>Layer behaves differently based on input type:</p><ol><li>A tripe of <code>(h, u, v)</code>, where <code>u</code> and <code>v</code> itself are tuples of length <code>N</code>, the <code>layers</code> is also a tuple of length <code>N</code>. The computation is as follows</li></ol><pre><code class="language-julia hljs">for i in 1:N
    h = connection(layers[i](h), u[i], v[i])
end</code></pre><ol><li>A triple of <code>(h, u, v)</code>, where <code>u</code> and <code>v</code> are <code>AbstractArray</code>s.</li></ol><pre><code class="language-julia hljs">for i in 1:N
    h = connection(layers[i](h), u, v)
end</code></pre><p><strong>Parameters</strong></p><ul><li>Parameters of each <code>layer</code> wrapped in a NamedTuple with <code>fields = layer_1, layer_2, ..., layer_N</code></li></ul><p><strong>States</strong></p><ul><li>States of each <code>layer</code> wrapped in a NamedTuple with <code>fields = layer_1, layer_2, ..., layer_N</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/layers/containers.jl#L2-L48">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.BACON-Tuple{Int64, Int64, Int64, Real}" href="#Sophon.BACON-Tuple{Int64, Int64, Int64, Real}"><code>Sophon.BACON</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">BACON(in_dims::Int, out_dims::Int, N::Int, period::Real; hidden_dims::Int, num_layers::Int)</code></pre><p>Band-limited Coordinate Networks (BACON) from <a href="references/#lindell2021bacon">David B. Lindell, Dave Van Veen, Jeong Joon Park, Gordon Wetzstein (2021)</a>. Similar to <a href="#Sophon.FourierFilterNet-Tuple{Int64, Int64}"><code>FourierFilterNet</code></a> but the frequcies are dicrete and nontrainable.</p><p>Tips: It is recommended to set <code>period</code> to be <code>1,2,π</code> or <code>2π</code> for better performance.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/layers/nets.jl#L393-L400">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.FourierAttention" href="#Sophon.FourierAttention"><code>Sophon.FourierAttention</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">FourierAttention(in_dims::Int, out_dims::Int, activation::Function=sin;
                 hidden_dims::Int=512, num_layers::Int=6, modes::NTuple)</code></pre><pre><code class="nohighlight hljs">x → [FourierFeature(x); x] → PINNAttention</code></pre><p><strong>Arguments</strong></p><ul><li><code>in_dims</code>: The input dimension.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>modes</code>: A tuple of pairs of random frequencies and the number of samples.</li><li><code>hidden_dim</code>: The hidden dimension of each hidden layer.</li><li><code>num_layers</code>: The number of hidden layers.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; FourierAttention(3, 1, sin; hidden_dims=10, num_layers=3,
                        modes=(1 =&gt; 10, 10 =&gt; 10, 50 =&gt; 10))
Chain(
    layer_1 = SkipConnection(
        FourierFeature(3 =&gt; 60),
        vcat
    ),
    layer_2 = PINNAttention(
        H_net = Dense(63 =&gt; 10, sin),   # 640 parameters
        U_net = Dense(63 =&gt; 10, sin),   # 640 parameters
        V_net = Dense(63 =&gt; 10, sin),   # 640 parameters
        fusion = TriplewiseFusion(
            layers = (layer_1 = Dense(10 =&gt; 10, sin), layer_2 = Dense(10 =&gt; 10, sin), layer_3 = Dense(10 =&gt; 10, sin), layer_4 = Dense(10 =&gt; 1)),  # 341 parameters
        ),
    ),
)         # Total: 2_261 parameters,
          #        plus 90 states, summarysize 176 bytes.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/layers/nets.jl#L74-L113">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.FourierFilterNet-Tuple{Int64, Int64}" href="#Sophon.FourierFilterNet-Tuple{Int64, Int64}"><code>Sophon.FourierFilterNet</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">FourierFilterNet(in_dims::Int, out_dims::Int; hidden_dims::Int, num_layers::Int,
                 bandwidth::Real)</code></pre><p><strong>Keyword Arguments</strong></p><ul><li><code>bandwidth</code>: The maximum bandwidth of the network. The bandwidth is the sum of each filter&#39;s bandwidth.</li></ul><p><strong>Parameters</strong></p><ul><li>Parameters of the filters:</li></ul><p class="math-container">\[    W\sim \mathcal{U}(-\frac{ω}{n}, \frac{ω}{n}), \quad b\sim \mathcal{U}(-\pi, \pi),\]</p><p>where <code>n</code> is the number of filters.</p><p>For a periodic function with period <span>$P$</span>, the Fourier series in amplitude-phase form is</p><p class="math-container">\[s_N(x)=\frac{a_0}{2}+\sum_{n=1}^N{a_n}\cdot \sin \left( \frac{2\pi}{P}nx+\varphi _n \right)\]</p><p>We have the following relation between the banthwidth and the parameters of the model:</p><p class="math-container">\[ω = 2πB=\frac{2πN}{P}.\]</p><p>where <span>$B$</span> is the bandwidth of the network.</p><p><strong>References</strong></p><p><a href="references/#fathony2021multiplicative">Rizal Fathony, Anit Kumar Sahu, Devin Willmott, J Zico Kolter (2021)</a></p><p><a href="references/#lindell2021bacon">David B. Lindell, Dave Van Veen, Jeong Joon Park, Gordon Wetzstein (2021)</a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/layers/nets.jl#L344-L373">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.FourierNet-Union{Tuple{T}, Tuple{N}, Tuple{Tuple{Vararg{T, N}}, Function, Tuple{Vararg{T, N}} where {N, T}}} where {N, T&lt;:Int64}" href="#Sophon.FourierNet-Union{Tuple{T}, Tuple{N}, Tuple{Tuple{Vararg{T, N}}, Function, Tuple{Vararg{T, N}} where {N, T}}} where {N, T&lt;:Int64}"><code>Sophon.FourierNet</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">FourierNet(ayer_sizes::NTuple, activation, modes::NTuple)</code></pre><p>A model that combines <a href="#Sophon.FourierFeature"><code>FourierFeature</code></a> and <a href="#Sophon.FullyConnected-Union{Tuple{T}, Tuple{N}, Tuple{Tuple{Vararg{T, N}}, Function}} where {N, T&lt;:Int64}"><code>FullyConnected</code></a>.</p><pre><code class="nohighlight hljs">x → FourierFeature → FullyConnected → y</code></pre><p><strong>Arguments</strong></p><ul><li><code>in_dims</code>: The number of input dimensions.</li><li><code>layer_sizes</code>: A tuple of hidden dimensions used to construct <code>FullyConnected</code>.</li><li><code>activation</code>: The activation function used to construct <code>FullyConnected</code>.</li><li><code>modes</code>: A tuple of modes used to construct <code>FourierFeature</code>.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; FourierNet((2, 30, 30, 1), sin, (1 =&gt; 10, 10 =&gt; 10, 50 =&gt; 10))
Chain(
    layer_1 = FourierFeature(2 =&gt; 60),
    layer_2 = Dense(60 =&gt; 30, sin),     # 1_830 parameters
    layer_3 = Dense(30 =&gt; 30, sin),     # 930 parameters
    layer_4 = Dense(30 =&gt; 1),           # 31 parameters
)         # Total: 2_791 parameters,
          #        plus 60 states, summarysize 112 bytes.

julia&gt; FourierNet((2, 30, 30, 1), sin, (1, 2, 3, 4))
Chain(
    layer_1 = FourierFeature(2 =&gt; 16),
    layer_2 = Dense(16 =&gt; 30, sin),     # 510 parameters
    layer_3 = Dense(30 =&gt; 30, sin),     # 930 parameters
    layer_4 = Dense(30 =&gt; 1),           # 31 parameters
)         # Total: 1_471 parameters,
          #        plus 4 states, summarysize 96 bytes.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/layers/nets.jl#L124-L161">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.FullyConnected-Union{Tuple{T}, Tuple{N}, Tuple{Tuple{Vararg{T, N}}, Function}} where {N, T&lt;:Int64}" href="#Sophon.FullyConnected-Union{Tuple{T}, Tuple{N}, Tuple{Tuple{Vararg{T, N}}, Function}} where {N, T&lt;:Int64}"><code>Sophon.FullyConnected</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">FullyConnected(layer_sizes::NTuple{N, Int}, activation; outermost = true,
               init_weight = kaiming_uniform(activation),
               init_bias = zeros32)
FullyConnected(in_dims::Int, out_dims::Int, activation::Function;
               hidden_dims::Int, num_layers::Int, outermost=true,
               init_weight = kaiming_uniform(activation),
               init_bias = zeros32)</code></pre><p>Create fully connected layers.</p><p><strong>Arguments</strong></p><ul><li><code>layer_sizes</code>: Number of dimensions of each layer.</li><li><code>hidden_dims</code>: Number of hidden dimensions.</li><li><code>num_layers</code>: Number of layers.</li><li><code>activation</code>: Activation function.</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>outermost</code>: Whether to use activation function for the last layer. If <code>false</code>, the activation function is applied to the output of the last layer.</li><li><code>init_weight</code>: Initialization method for the weights.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">julia&gt; fc = FullyConnected((1, 12, 24, 32), relu)
Chain(
    layer_1 = Dense(1 =&gt; 12, relu),     # 24 parameters
    layer_2 = Dense(12 =&gt; 24, relu),    # 312 parameters
    layer_3 = Dense(24 =&gt; 32),          # 800 parameters
)         # Total: 1_136 parameters,
          #        plus 0 states, summarysize 48 bytes.

julia&gt; fc = FullyConnected(1, 10, relu; hidden_dims=20, num_layers=3)
Chain(
    layer_1 = Dense(1 =&gt; 20, relu),     # 40 parameters
    layer_2 = Dense(20 =&gt; 20, relu),    # 420 parameters
    layer_3 = Dense(20 =&gt; 20, relu),    # 420 parameters
    layer_4 = Dense(20 =&gt; 10),          # 210 parameters
)         # Total: 1_090 parameters,
          #        plus 0 states, summarysize 64 bytes.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/layers/nets.jl#L243-L287">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.Sine-Union{Tuple{Pair{T, T}}, Tuple{T}} where T&lt;:Int64" href="#Sophon.Sine-Union{Tuple{Pair{T, T}}, Tuple{T}} where T&lt;:Int64"><code>Sophon.Sine</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Sine(in_dims::Int, out_dims::Int; omega::Real)</code></pre><p>Sinusoidal layer.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">s = Sine(2, 2; omega=30.0f0) # first layer
s = Sine(2, 2) # hidden layer</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/layers/basic.jl#L196-L207">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.Siren-Tuple{Int64, Int64}" href="#Sophon.Siren-Tuple{Int64, Int64}"><code>Sophon.Siren</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Siren(in_dims::Int, out_dims::Int; hidden_dims::Int, num_layers::Int, omega=30.0f0,
      init_weight=nothing))
Siren(layer_sizes::Int...; omega=30.0f0, init_weight=nothing)</code></pre><p>Sinusoidal Representation Network.</p><p><strong>Keyword Arguments</strong></p><ul><li><code>omega</code>: The <code>ω₀</code> used for the first layer.</li><li><code>init_weight</code>: The initialization algorithm for the weights of the <strong>input</strong> layer. Note that all hidden layers use <code>kaiming_uniform</code> as the initialization algorithm. The default is<p class="math-container">\[    W\sim \mathcal{U}\left(-\frac{\omega}{fan_{in}}, \frac{\omega}{fan_{in}}\right)\]</p></li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">julia&gt; Siren(2, 32, 32, 1; omega=5.0f0)
Chain(
    layer_1 = Dense(2 =&gt; 32, sin),      # 96 parameters
    layer_2 = Dense(32 =&gt; 32, sin),     # 1_056 parameters
    layer_3 = Dense(32 =&gt; 1),           # 33 parameters
)         # Total: 1_185 parameters,
          #        plus 0 states, summarysize 48 bytes.

julia&gt; Siren(3, 1; hidden_dims=20, num_layers=3)
Chain(
    layer_1 = Dense(3 =&gt; 20, sin),      # 80 parameters
    layer_2 = Dense(20 =&gt; 20, sin),     # 420 parameters
    layer_3 = Dense(20 =&gt; 20, sin),     # 420 parameters
    layer_4 = Dense(20 =&gt; 1),           # 21 parameters
)         # Total: 941 parameters,
          #        plus 0 states, summarysize 64 bytes.

# Use your own initialization algorithm for the input layer.
julia&gt; init_weight(rng::AbstractRNG, out_dims::Int, in_dims::Int) = randn(rng, Float32, out_dims, in_dims) .* 2.5f0
julia&gt; chain = Siren(2, 1; num_layers = 4, hidden_dims = 50, init_weight = init_weight)</code></pre><p><strong>Reference</strong></p><p><a href="references/#sitzmann2020implicit">Vincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, Gordon Wetzstein (2020)</a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/layers/nets.jl#L169-L214">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Sophon.gaussian" href="#Sophon.gaussian"><code>Sophon.gaussian</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">gaussian(x, a=0.2)</code></pre><p>The Gaussian activation function.</p><p class="math-container">\[e^{\frac{- x^{2}}{2a^{2}}}\]</p><p><strong>Reference</strong></p><p><a href="references/#ramasinghe2021beyond">Sameera Ramasinghe, Simon Lucey (2021)</a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/YichengDWu/Sophon.jl/blob/0afdea7e235c4fb56e4358727ec1599840e191c7/src/activations.jl#L1-L11">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="tutorials/discontinuous/">Fitting a nonlinear discontinuous function »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Saturday 24 September 2022 04:43">Saturday 24 September 2022</span>. Using Julia version 1.8.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
