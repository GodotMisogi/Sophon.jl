<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Fitting a nonlinear discontinuous function · Sophon.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://MilkshakeForReal.github.io/Sophon.jl/tutorials/discontinuous/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/indigo.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Sophon.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li class="is-active"><a class="tocitem" href>Fitting a nonlinear discontinuous function</a><ul class="internal"><li><a class="tocitem" href="#Import-pacakges"><span>Import pacakges</span></a></li><li><a class="tocitem" href="#Dataset"><span>Dataset</span></a></li><li><a class="tocitem" href="#Naive-Neural-Nets"><span>Naive Neural Nets</span></a></li><li><a class="tocitem" href="#Siren"><span>Siren</span></a></li><li><a class="tocitem" href="#Gaussian-activation-function"><span>Gaussian activation function</span></a></li><li><a class="tocitem" href="#Quadratic-activation-function"><span>Quadratic activation function</span></a></li><li><a class="tocitem" href="#Conclusion"><span>Conclusion</span></a></li></ul></li><li><a class="tocitem" href="../poisson/">1D Poisson&#39;s Equation</a></li><li><a class="tocitem" href="../convection/">1D Convection Equation</a></li><li><a class="tocitem" href="../helmholtz/">2D Helmholtz Equation</a></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Fitting a nonlinear discontinuous function</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Fitting a nonlinear discontinuous function</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/MilkshakeForReal/Sophon.jl/blob/main/docs/src/tutorials/discontinuous.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Fitting-a-nonlinear-discontinuous-function"><a class="docs-heading-anchor" href="#Fitting-a-nonlinear-discontinuous-function">Fitting a nonlinear discontinuous function</a><a id="Fitting-a-nonlinear-discontinuous-function-1"></a><a class="docs-heading-anchor-permalink" href="#Fitting-a-nonlinear-discontinuous-function" title="Permalink"></a></h1><p>This example is taken from <a href="https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.2020.0334">here</a>. However, we do not use adaptive activation functions. Instead, we show that using suitable non-parametric activation functions immediately performs better.</p><p>The following  discontinuous  function  with  discontinuity  at <span>$x=0$</span>  location  is approximated by <a href="../../#Sophon.Siren-Tuple{Int64, Int64}"><code>Siren</code></a>.</p><p class="math-container">\[u(x)= \begin{cases}0.2 \sin (18 x) &amp; \text { if } x \leq 0 \\ 1+0.3 x \cos (54 x) &amp; \text { otherwise }\end{cases}\]</p><p>The domain is <span>$[-1,1]$</span>. The number of training points used is <code>300</code>.</p><h2 id="Import-pacakges"><a class="docs-heading-anchor" href="#Import-pacakges">Import pacakges</a><a id="Import-pacakges-1"></a><a class="docs-heading-anchor-permalink" href="#Import-pacakges" title="Permalink"></a></h2><pre><code class="language-julia hljs">using Lux, Sophon
using NNlib, Optimisers, Plots, Random, Statistics, Zygote</code></pre><h2 id="Dataset"><a class="docs-heading-anchor" href="#Dataset">Dataset</a><a id="Dataset-1"></a><a class="docs-heading-anchor-permalink" href="#Dataset" title="Permalink"></a></h2><pre><code class="language-julia hljs">function u(x)
    if x &lt;= 0
        return 0.2 * sin(18 * x)
    else
        return 1 + 0.3 * x * cos(54 * x)
    end
end

function generate_data(n=300)
    x = reshape(collect(range(-1.0f0, 1.0f0, n)), (1, n))
    y = u.(x)
    return (x, y)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">generate_data (generic function with 2 methods)</code></pre><p>Let&#39;s visualize the data.</p><pre><code class="language-julia hljs">x, y = generate_data()
Plots.plot(vec(x), vec(y),label=false)</code></pre><p><img src="../u.svg" alt/></p><h2 id="Naive-Neural-Nets"><a class="docs-heading-anchor" href="#Naive-Neural-Nets">Naive Neural Nets</a><a id="Naive-Neural-Nets-1"></a><a class="docs-heading-anchor-permalink" href="#Naive-Neural-Nets" title="Permalink"></a></h2><p>First we demonstrate show naive fully connected neural nets could be really bad at fitting this function.</p><pre><code class="language-julia hljs">model = FullyConnected((1,50,50,50,50,1), relu)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
    layer_1 = Dense(1 =&gt; 50, relu),     # 100 parameters
    layer_2 = Dense(50 =&gt; 50, relu),    # 2_550 parameters
    layer_3 = Dense(50 =&gt; 50, relu),    # 2_550 parameters
    layer_4 = Dense(50 =&gt; 50, relu),    # 2_550 parameters
    layer_5 = Dense(50 =&gt; 1),           # 51 parameters
)         # Total: 7_801 parameters,
          #        plus 0 states, summarysize 80 bytes.</code></pre><h3 id="Train-the-model"><a class="docs-heading-anchor" href="#Train-the-model">Train the model</a><a id="Train-the-model-1"></a><a class="docs-heading-anchor-permalink" href="#Train-the-model" title="Permalink"></a></h3><pre><code class="language-julia hljs">function train(model)
    ps, st = Lux.setup(Random.default_rng(), model)
    opt = Adam()
    st_opt = Optimisers.setup(opt,ps)
    function loss(model, ps, st, x, y)
        y_pred, _ = model(x, ps, st)
        mes = mean(abs2, y_pred .- y)
        return mes
    end

    for i in 1:2000
        gs = gradient(p-&gt;loss(model,p,st,x,y), ps)[1]
        st_opt, ps = Optimisers.update(st_opt, ps, gs)
        if i % 100 == 1 || i == 2000
            println(&quot;Epoch $i ||  &quot;, loss(model,ps,st,x,y))
        end
    end
    return ps, st
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">train (generic function with 1 method)</code></pre><h3 id="Plot-The-Result"><a class="docs-heading-anchor" href="#Plot-The-Result">Plot The Result</a><a id="Plot-The-Result-1"></a><a class="docs-heading-anchor-permalink" href="#Plot-The-Result" title="Permalink"></a></h3><pre><code class="language-julia hljs">@time ps, st = train(model)
y_pred = model(x,ps,st)[1]
Plots.plot(vec(x), vec(y_pred),label=&quot;Prediction&quot;,line = (:dot, 4))
Plots.plot!(vec(x), vec(y),label=&quot;Exact&quot;,legend=:topleft)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Epoch 1 ||  1.4402252313047557
Epoch 101 ||  0.020744725734010854
Epoch 201 ||  0.016424537305544856
Epoch 301 ||  0.014968464354743324
Epoch 401 ||  0.013472030365916812
Epoch 501 ||  0.012759351895751924
Epoch 601 ||  0.01251596176040665
Epoch 701 ||  0.012424372003479855
Epoch 801 ||  0.012340821643218062
Epoch 901 ||  0.012171530749195943
Epoch 1001 ||  0.011896039150251617
Epoch 1101 ||  0.011349686698831065
Epoch 1201 ||  0.010103801189969832
Epoch 1301 ||  0.008976609242567192
Epoch 1401 ||  0.007940380115176223
Epoch 1501 ||  0.00774101832580307
Epoch 1601 ||  0.007720001507244538
Epoch 1701 ||  0.007900113309982817
Epoch 1801 ||  0.007675233424925585
Epoch 1901 ||  0.007671204657651323
Epoch 2000 ||  0.0076748951755968905
 32.563951 seconds (30.42 M allocations: 4.528 GiB, 2.74% gc time, 95.35% compilation time)</code></pre><p><img src="../result1.svg" alt/></p><h2 id="Siren"><a class="docs-heading-anchor" href="#Siren">Siren</a><a id="Siren-1"></a><a class="docs-heading-anchor-permalink" href="#Siren" title="Permalink"></a></h2><p>We use four hidden layers with 50 neurons in each.</p><pre><code class="language-julia hljs">model = Siren(1,50,50,50,50,1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
    layer_1 = Dense(1 =&gt; 50, sin),      # 100 parameters
    layer_2 = Dense(50 =&gt; 50, sin),     # 2_550 parameters
    layer_3 = Dense(50 =&gt; 50, sin),     # 2_550 parameters
    layer_4 = Dense(50 =&gt; 50, sin),     # 2_550 parameters
    layer_5 = Dense(50 =&gt; 1),           # 51 parameters
)         # Total: 7_801 parameters,
          #        plus 0 states, summarysize 88 bytes.</code></pre><pre><code class="language-julia hljs">@time ps, st = train(model)
y_pred = model(x,ps,st)[1]
Plots.plot(vec(x), vec(y_pred),label=&quot;Prediction&quot;,line = (:dot, 4))
Plots.plot!(vec(x), vec(y),label=&quot;Exact&quot;,legend=:topleft)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Epoch 1 ||  1.0320505066604733
Epoch 101 ||  0.00229938505307869
Epoch 201 ||  0.0007997857925430192
Epoch 301 ||  0.0006090323891397143
Epoch 401 ||  0.0005191058242566402
Epoch 501 ||  0.00045540452804143064
Epoch 601 ||  0.00040365861762076566
Epoch 701 ||  0.0003571897749446294
Epoch 801 ||  0.00031308773645189137
Epoch 901 ||  0.0002708914341039096
Epoch 1001 ||  0.00023110324720291726
Epoch 1101 ||  0.0001942022225140314
Epoch 1201 ||  0.00016041703687791453
Epoch 1301 ||  0.00012987137642337724
Epoch 1401 ||  0.00010272198128727384
Epoch 1501 ||  7.923778087303442e-5
Epoch 1601 ||  5.975183723150871e-5
Epoch 1701 ||  4.440900417331066e-5
Epoch 1801 ||  3.2979095341423935e-5
Epoch 1901 ||  2.4890145801181177e-5
Epoch 2000 ||  1.943704192211398e-5
 14.339867 seconds (17.96 M allocations: 4.792 GiB, 4.75% gc time, 77.49% compilation time)</code></pre><p><img src="../result.svg" alt/></p><h2 id="Gaussian-activation-function"><a class="docs-heading-anchor" href="#Gaussian-activation-function">Gaussian activation function</a><a id="Gaussian-activation-function-1"></a><a class="docs-heading-anchor-permalink" href="#Gaussian-activation-function" title="Permalink"></a></h2><p>We can also try using a fully connected net with the <a href="../../#Sophon.gaussian"><code>gaussian</code></a> activation function.</p><pre><code class="language-julia hljs">model = FullyConnected((1,50,50,50,50,1), gaussian)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
    layer_1 = Dense(1 =&gt; 50, gaussian),  # 100 parameters
    layer_2 = Dense(50 =&gt; 50, gaussian),  # 2_550 parameters
    layer_3 = Dense(50 =&gt; 50, gaussian),  # 2_550 parameters
    layer_4 = Dense(50 =&gt; 50, gaussian),  # 2_550 parameters
    layer_5 = Dense(50 =&gt; 1),           # 51 parameters
)         # Total: 7_801 parameters,
          #        plus 0 states, summarysize 80 bytes.</code></pre><pre><code class="language-julia hljs">@time ps, st = train(model)
y_pred = model(x,ps,st)[1]
Plots.plot(vec(x), vec(y_pred),label=&quot;Prediction&quot;,line = (:dot, 4))
Plots.plot!(vec(x), vec(y),label=&quot;Exact&quot;,legend=:topleft)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Epoch 1 ||  0.3178349431716634
Epoch 101 ||  0.007745625131310723
Epoch 201 ||  0.00488346050867273
Epoch 301 ||  0.0022073873524476643
Epoch 401 ||  0.0005300252516659086
Epoch 501 ||  0.00036941278787732486
Epoch 601 ||  0.0001971883624649472
Epoch 701 ||  0.0002905604367087781
Epoch 801 ||  4.093275020569233e-5
Epoch 901 ||  2.1179532208450533e-5
Epoch 1001 ||  1.2646896062994811e-5
Epoch 1101 ||  8.359070569002767e-6
Epoch 1201 ||  6.221247101975988e-6
Epoch 1301 ||  0.00017369760408150934
Epoch 1401 ||  3.9864006741631015e-6
Epoch 1501 ||  4.4509302205203574e-5
Epoch 1601 ||  2.9591222559513634e-6
Epoch 1701 ||  2.467619066439598e-6
Epoch 1801 ||  7.3732372525728475e-6
Epoch 1901 ||  3.362238989166065e-6
Epoch 2000 ||  2.496992207151894e-6
 11.922684 seconds (14.14 M allocations: 4.473 GiB, 4.44% gc time, 74.05% compilation time)</code></pre><p><img src="../result2.svg" alt/></p><h2 id="Quadratic-activation-function"><a class="docs-heading-anchor" href="#Quadratic-activation-function">Quadratic activation function</a><a id="Quadratic-activation-function-1"></a><a class="docs-heading-anchor-permalink" href="#Quadratic-activation-function" title="Permalink"></a></h2><p><a href="tutorials/@ref"><code>quadratic</code></a> is much cheaper to compute compared to the Gaussain activation function.</p><pre><code class="language-julia hljs">model = FullyConnected((1,50,50,50,50,1), quadratic)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
    layer_1 = Dense(1 =&gt; 50, quadratic),  # 100 parameters
    layer_2 = Dense(50 =&gt; 50, quadratic),  # 2_550 parameters
    layer_3 = Dense(50 =&gt; 50, quadratic),  # 2_550 parameters
    layer_4 = Dense(50 =&gt; 50, quadratic),  # 2_550 parameters
    layer_5 = Dense(50 =&gt; 1),           # 51 parameters
)         # Total: 7_801 parameters,
          #        plus 0 states, summarysize 80 bytes.</code></pre><pre><code class="language-julia hljs">@time ps, st = train(model)
y_pred = model(x,ps,st)[1]
Plots.plot(vec(x), vec(y_pred),label=&quot;Prediction&quot;,line = (:dot, 4))
Plots.plot!(vec(x), vec(y),label=&quot;Exact&quot;,legend=:topleft)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Epoch 1 ||  0.3770985314168118
Epoch 101 ||  0.007348670178855455
Epoch 201 ||  0.006102650201928739
Epoch 301 ||  0.005129132551397169
Epoch 401 ||  0.003974586266413221
Epoch 501 ||  0.002655614097227091
Epoch 601 ||  0.0011312255711813772
Epoch 701 ||  0.00022611404140141533
Epoch 801 ||  0.0001660685732893611
Epoch 901 ||  4.4287186518886034e-5
Epoch 1001 ||  3.0161710432061007e-5
Epoch 1101 ||  2.426175295835345e-5
Epoch 1201 ||  1.676039449800981e-5
Epoch 1301 ||  1.2565915259047241e-5
Epoch 1401 ||  1.6113798628076956e-5
Epoch 1501 ||  1.040771186377687e-5
Epoch 1601 ||  8.00142013096324e-6
Epoch 1701 ||  6.412546753003935e-6
Epoch 1801 ||  6.041031014333993e-6
Epoch 1901 ||  7.392528266358896e-6
Epoch 2000 ||  3.9103291809771e-6
  9.537439 seconds (12.36 M allocations: 4.351 GiB, 4.58% gc time, 81.89% compilation time)</code></pre><p><img src="../result3.svg" alt/></p><h2 id="Conclusion"><a class="docs-heading-anchor" href="#Conclusion">Conclusion</a><a id="Conclusion-1"></a><a class="docs-heading-anchor-permalink" href="#Conclusion" title="Permalink"></a></h2><p>There are many misconceptions about the so-called &quot;Spectral bias&quot;. Mainstream attributes the phenomenon that neural networks &quot;suppress&quot; high frequencies to gradient descent. This is not the whole picture. Initialization also plays an important role. Siren solves this problem by initializing larger weights in the first layer, while activation functions such as gassian have large enough gradients themselves. Please refer to <a href="../../references/#sitzmann2020implicit">Vincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, Gordon Wetzstein (2020)</a>, <a href="../../references/#ramasinghe2021beyond">Sameera Ramasinghe, Simon Lucey (2021)</a> and <a href="../../references/#ramasinghe2022regularizing">Sameera Ramasinghe, Lachlan MacDonald, Simon Lucey (2022)</a> if you want to dive deeper into this.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Home</a><a class="docs-footer-nextpage" href="../poisson/">1D Poisson&#39;s Equation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.22 on <span class="colophon-date" title="Wednesday 31 August 2022 19:22">Wednesday 31 August 2022</span>. Using Julia version 1.8.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
