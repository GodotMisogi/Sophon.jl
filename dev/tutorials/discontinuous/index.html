<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Fitting a nonlinear discontinuous function · Sophon.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://MilkshakeForReal.github.io/Sophon.jl/tutorials/discontinuous/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/indigo.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Sophon.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li class="is-active"><a class="tocitem" href>Fitting a nonlinear discontinuous function</a><ul class="internal"><li><a class="tocitem" href="#Import-pacakges"><span>Import pacakges</span></a></li><li><a class="tocitem" href="#Dataset"><span>Dataset</span></a></li><li><a class="tocitem" href="#Naive-Neural-Nets"><span>Naive Neural Nets</span></a></li><li><a class="tocitem" href="#Siren"><span>Siren</span></a></li><li><a class="tocitem" href="#Gaussian-activation-function"><span>Gaussian activation function</span></a></li><li><a class="tocitem" href="#Quadratic-activation-function"><span>Quadratic activation function</span></a></li><li><a class="tocitem" href="#Conclusion"><span>Conclusion</span></a></li></ul></li><li><a class="tocitem" href="../poisson/">1D Poisson&#39;s Equation</a></li><li><a class="tocitem" href="../convection/">1D Convection Equation</a></li><li><a class="tocitem" href="../helmholtz/">2D Helmholtz Equation</a></li></ul></li><li><a class="tocitem" href="../../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Fitting a nonlinear discontinuous function</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Fitting a nonlinear discontinuous function</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/MilkshakeForReal/Sophon.jl/blob/main/docs/src/tutorials/discontinuous.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Fitting-a-nonlinear-discontinuous-function"><a class="docs-heading-anchor" href="#Fitting-a-nonlinear-discontinuous-function">Fitting a nonlinear discontinuous function</a><a id="Fitting-a-nonlinear-discontinuous-function-1"></a><a class="docs-heading-anchor-permalink" href="#Fitting-a-nonlinear-discontinuous-function" title="Permalink"></a></h1><p>This example is taken from <a href="https://royalsocietypublishing.org/doi/epdf/10.1098/rspa.2020.0334">here</a>. However, we do not use adaptive activation functions. Instead, we show that using suitable non-parametric activation functions immediately performs better.</p><p>The following  discontinuous  function  with  discontinuity  at <span>$x=0$</span>  location  is approximated by <a href="../../#Sophon.Siren-Tuple{Int64, Int64}"><code>Siren</code></a>.</p><p class="math-container">\[u(x)= \begin{cases}0.2 \sin (18 x) &amp; \text { if } x \leq 0 \\ 1+0.3 x \cos (54 x) &amp; \text { otherwise }\end{cases}\]</p><p>The domain is <span>$[-1,1]$</span>. The number of training points used is <code>300</code>.</p><h2 id="Import-pacakges"><a class="docs-heading-anchor" href="#Import-pacakges">Import pacakges</a><a id="Import-pacakges-1"></a><a class="docs-heading-anchor-permalink" href="#Import-pacakges" title="Permalink"></a></h2><pre><code class="language-julia hljs">using Lux, Sophon
using NNlib, Optimisers, Plots, Random, Statistics, Zygote</code></pre><h2 id="Dataset"><a class="docs-heading-anchor" href="#Dataset">Dataset</a><a id="Dataset-1"></a><a class="docs-heading-anchor-permalink" href="#Dataset" title="Permalink"></a></h2><pre><code class="language-julia hljs">function u(x)
    if x &lt;= 0
        return 0.2 * sin(18 * x)
    else
        return 1 + 0.3 * x * cos(54 * x)
    end
end

function generate_data(n=300)
    x = reshape(collect(range(-1.0f0, 1.0f0, n)), (1, n))
    y = u.(x)
    return (x, y)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">generate_data (generic function with 2 methods)</code></pre><p>Let&#39;s visualize the data.</p><pre><code class="language-julia hljs">x, y = generate_data()
Plots.plot(vec(x), vec(y),label=false)</code></pre><p><img src="../u.svg" alt/></p><h2 id="Naive-Neural-Nets"><a class="docs-heading-anchor" href="#Naive-Neural-Nets">Naive Neural Nets</a><a id="Naive-Neural-Nets-1"></a><a class="docs-heading-anchor-permalink" href="#Naive-Neural-Nets" title="Permalink"></a></h2><p>First we demonstrate show naive fully connected neural nets could be really bad at fitting this function.</p><pre><code class="language-julia hljs">model = FullyConnected((1,50,50,50,50,1), relu)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
    layer_1 = Dense(1 =&gt; 50, relu),     # 100 parameters
    layer_2 = Dense(50 =&gt; 50, relu),    # 2_550 parameters
    layer_3 = Dense(50 =&gt; 50, relu),    # 2_550 parameters
    layer_4 = Dense(50 =&gt; 50, relu),    # 2_550 parameters
    layer_5 = Dense(50 =&gt; 1),           # 51 parameters
)         # Total: 7_801 parameters,
          #        plus 0 states, summarysize 80 bytes.</code></pre><h3 id="Train-the-model"><a class="docs-heading-anchor" href="#Train-the-model">Train the model</a><a id="Train-the-model-1"></a><a class="docs-heading-anchor-permalink" href="#Train-the-model" title="Permalink"></a></h3><pre><code class="language-julia hljs">function train(model)
    ps, st = Lux.setup(Random.default_rng(), model)
    opt = Adam()
    st_opt = Optimisers.setup(opt,ps)
    function loss(model, ps, st, x, y)
        y_pred, _ = model(x, ps, st)
        mes = mean(abs2, y_pred .- y)
        return mes
    end

    for i in 1:2000
        gs = gradient(p-&gt;loss(model,p,st,x,y), ps)[1]
        st_opt, ps = Optimisers.update(st_opt, ps, gs)
        if i % 100 == 1 || i == 2000
            println(&quot;Epoch $i ||  &quot;, loss(model,ps,st,x,y))
        end
    end
    return ps, st
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">train (generic function with 1 method)</code></pre><h3 id="Plot-The-Result"><a class="docs-heading-anchor" href="#Plot-The-Result">Plot The Result</a><a id="Plot-The-Result-1"></a><a class="docs-heading-anchor-permalink" href="#Plot-The-Result" title="Permalink"></a></h3><pre><code class="language-julia hljs">@time ps, st = train(model)
y_pred = model(x,ps,st)[1]
Plots.plot(vec(x), vec(y_pred),label=&quot;Prediction&quot;,line = (:dot, 4))
Plots.plot!(vec(x), vec(y),label=&quot;Exact&quot;,legend=:topleft)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Epoch 1 ||  1.2446309007509584
Epoch 101 ||  0.019161130097687485
Epoch 201 ||  0.01670577137586012
Epoch 301 ||  0.01583528376979103
Epoch 401 ||  0.015271753393325786
Epoch 501 ||  0.014817293969278349
Epoch 601 ||  0.014389025097668021
Epoch 701 ||  0.013783572418678268
Epoch 801 ||  0.01326033463425527
Epoch 901 ||  0.01275502313430854
Epoch 1001 ||  0.012368609109561536
Epoch 1101 ||  0.011802053767996513
Epoch 1201 ||  0.0108605112530172
Epoch 1301 ||  0.009513086378533774
Epoch 1401 ||  0.008286041281803542
Epoch 1501 ||  0.007899350135760696
Epoch 1601 ||  0.0077853400261141
Epoch 1701 ||  0.007748696837131811
Epoch 1801 ||  0.0077413191680235785
Epoch 1901 ||  0.007725893219439125
Epoch 2000 ||  0.00773828760006174
 33.335815 seconds (30.49 M allocations: 4.531 GiB, 3.05% gc time, 94.84% compilation time)</code></pre><p><img src="../result1.svg" alt/></p><h2 id="Siren"><a class="docs-heading-anchor" href="#Siren">Siren</a><a id="Siren-1"></a><a class="docs-heading-anchor-permalink" href="#Siren" title="Permalink"></a></h2><p>We use four hidden layers with 50 neurons in each.</p><pre><code class="language-julia hljs">model = Siren(1,50,50,50,50,1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
    layer_1 = Dense(1 =&gt; 50, sin),      # 100 parameters
    layer_2 = Dense(50 =&gt; 50, sin),     # 2_550 parameters
    layer_3 = Dense(50 =&gt; 50, sin),     # 2_550 parameters
    layer_4 = Dense(50 =&gt; 50, sin),     # 2_550 parameters
    layer_5 = Dense(50 =&gt; 1),           # 51 parameters
)         # Total: 7_801 parameters,
          #        plus 0 states, summarysize 88 bytes.</code></pre><pre><code class="language-julia hljs">@time ps, st = train(model)
y_pred = model(x,ps,st)[1]
Plots.plot(vec(x), vec(y_pred),label=&quot;Prediction&quot;,line = (:dot, 4))
Plots.plot!(vec(x), vec(y),label=&quot;Exact&quot;,legend=:topleft)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Epoch 1 ||  1.1712386020248036
Epoch 101 ||  0.0027852791607519143
Epoch 201 ||  0.000948464069923115
Epoch 301 ||  0.0007163339866673067
Epoch 401 ||  0.0006028920651838468
Epoch 501 ||  0.0005212430286648645
Epoch 601 ||  0.00045208161743048934
Epoch 701 ||  0.00038906977968811965
Epoch 801 ||  0.0003311596121876531
Epoch 901 ||  0.00027852367684418506
Epoch 1001 ||  0.00023021369803920332
Epoch 1101 ||  0.00018471102662770143
Epoch 1201 ||  0.00014152221980711675
Epoch 1301 ||  0.00010224053770103517
Epoch 1401 ||  7.047518506025752e-5
Epoch 1501 ||  4.887154629154906e-5
Epoch 1601 ||  3.595300269559433e-5
Epoch 1701 ||  2.8220058775167473e-5
Epoch 1801 ||  2.3123884840293208e-5
Epoch 1901 ||  1.9396024945697802e-5
Epoch 2000 ||  1.649904661899214e-5
 14.836636 seconds (18.00 M allocations: 4.788 GiB, 5.21% gc time, 78.00% compilation time)</code></pre><p><img src="../result.svg" alt/></p><h2 id="Gaussian-activation-function"><a class="docs-heading-anchor" href="#Gaussian-activation-function">Gaussian activation function</a><a id="Gaussian-activation-function-1"></a><a class="docs-heading-anchor-permalink" href="#Gaussian-activation-function" title="Permalink"></a></h2><p>We can also try using a fully connected net with the <a href="../../#Sophon.gaussian"><code>gaussian</code></a> activation function.</p><pre><code class="language-julia hljs">model = FullyConnected((1,50,50,50,50,1), gaussian)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
    layer_1 = Dense(1 =&gt; 50, gaussian),  # 100 parameters
    layer_2 = Dense(50 =&gt; 50, gaussian),  # 2_550 parameters
    layer_3 = Dense(50 =&gt; 50, gaussian),  # 2_550 parameters
    layer_4 = Dense(50 =&gt; 50, gaussian),  # 2_550 parameters
    layer_5 = Dense(50 =&gt; 1),           # 51 parameters
)         # Total: 7_801 parameters,
          #        plus 0 states, summarysize 80 bytes.</code></pre><pre><code class="language-julia hljs">@time ps, st = train(model)
y_pred = model(x,ps,st)[1]
Plots.plot(vec(x), vec(y_pred),label=&quot;Prediction&quot;,line = (:dot, 4))
Plots.plot!(vec(x), vec(y),label=&quot;Exact&quot;,legend=:topleft)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Epoch 1 ||  0.47319733850846574
Epoch 101 ||  0.007066363372038289
Epoch 201 ||  0.0028691571470522348
Epoch 301 ||  0.0006784621845569358
Epoch 401 ||  0.00029625265747594727
Epoch 501 ||  0.00011616711122972724
Epoch 601 ||  5.2829045692151335e-5
Epoch 701 ||  2.6480337869754094e-5
Epoch 801 ||  1.5444773140715443e-5
Epoch 901 ||  8.04719781722158e-5
Epoch 1001 ||  7.713218241828925e-6
Epoch 1101 ||  0.0026276394166614664
Epoch 1201 ||  7.325588108983095e-5
Epoch 1301 ||  2.1711293366338057e-5
Epoch 1401 ||  9.206375632912514e-6
Epoch 1501 ||  5.212441983278542e-6
Epoch 1601 ||  4.504517845533167e-6
Epoch 1701 ||  3.2207011978428495e-5
Epoch 1801 ||  7.972943608801465e-6
Epoch 1901 ||  8.563777423030493e-6
Epoch 2000 ||  1.8743055543932135e-6
 12.481908 seconds (14.17 M allocations: 4.471 GiB, 4.95% gc time, 73.85% compilation time)</code></pre><p><img src="../result2.svg" alt/></p><h2 id="Quadratic-activation-function"><a class="docs-heading-anchor" href="#Quadratic-activation-function">Quadratic activation function</a><a id="Quadratic-activation-function-1"></a><a class="docs-heading-anchor-permalink" href="#Quadratic-activation-function" title="Permalink"></a></h2><p><a href="tutorials/@ref"><code>quadratic</code></a> is much cheaper to compute compared to the Gaussain activation function.</p><pre><code class="language-julia hljs">model = FullyConnected((1,50,50,50,50,1), quadratic)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Chain(
    layer_1 = Dense(1 =&gt; 50, quadratic),  # 100 parameters
    layer_2 = Dense(50 =&gt; 50, quadratic),  # 2_550 parameters
    layer_3 = Dense(50 =&gt; 50, quadratic),  # 2_550 parameters
    layer_4 = Dense(50 =&gt; 50, quadratic),  # 2_550 parameters
    layer_5 = Dense(50 =&gt; 1),           # 51 parameters
)         # Total: 7_801 parameters,
          #        plus 0 states, summarysize 80 bytes.</code></pre><pre><code class="language-julia hljs">@time ps, st = train(model)
y_pred = model(x,ps,st)[1]
Plots.plot(vec(x), vec(y_pred),label=&quot;Prediction&quot;,line = (:dot, 4))
Plots.plot!(vec(x), vec(y),label=&quot;Exact&quot;,legend=:topleft)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Epoch 1 ||  0.3125204814747214
Epoch 101 ||  0.006645759824979266
Epoch 201 ||  0.005322093446121825
Epoch 301 ||  0.003935609416869098
Epoch 401 ||  0.002703329158550734
Epoch 501 ||  0.0014253430046067461
Epoch 601 ||  0.0005376255324139007
Epoch 701 ||  0.00017426489533555972
Epoch 801 ||  7.874309739130275e-5
Epoch 901 ||  5.348452914124083e-5
Epoch 1001 ||  4.2819634399104766e-5
Epoch 1101 ||  3.544513453033733e-5
Epoch 1201 ||  3.210589925244131e-5
Epoch 1301 ||  2.581992973370885e-5
Epoch 1401 ||  2.2123354671544725e-5
Epoch 1501 ||  2.021115591924837e-5
Epoch 1601 ||  3.65739442009991e-5
Epoch 1701 ||  1.4898533632267998e-5
Epoch 1801 ||  1.3403060106748805e-5
Epoch 1901 ||  1.2681413209267554e-5
Epoch 2000 ||  1.1176560241749162e-5
 10.119802 seconds (12.39 M allocations: 4.348 GiB, 5.86% gc time, 81.70% compilation time)</code></pre><p><img src="../result3.svg" alt/></p><h2 id="Conclusion"><a class="docs-heading-anchor" href="#Conclusion">Conclusion</a><a id="Conclusion-1"></a><a class="docs-heading-anchor-permalink" href="#Conclusion" title="Permalink"></a></h2><p>There are many misconceptions about the so-called &quot;Spectral bias&quot;. Mainstream attributes the phenomenon that neural networks &quot;suppress&quot; high frequencies to gradient descent. This is not the whole picture. Initialization also plays an important role. Siren solves this problem by initializing larger weights in the first layer, while activation functions such as gassian have large enough gradients themselves. Please refer to <a href="../../references/#sitzmann2020implicit">Vincent Sitzmann, Julien Martel, Alexander Bergman, David Lindell, Gordon Wetzstein (2020)</a>, <a href="../../references/#ramasinghe2021beyond">Sameera Ramasinghe, Simon Lucey (2021)</a> and <a href="../../references/#ramasinghe2022regularizing">Sameera Ramasinghe, Lachlan MacDonald, Simon Lucey (2022)</a> if you want to dive deeper into this.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Home</a><a class="docs-footer-nextpage" href="../poisson/">1D Poisson&#39;s Equation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.22 on <span class="colophon-date" title="Tuesday 30 August 2022 21:33">Tuesday 30 August 2022</span>. Using Julia version 1.8.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
